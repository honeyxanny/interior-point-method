{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyywEYv5-SOs"
      },
      "source": [
        "**Библиотеки**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "IF0wxVeX-RJU"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Callable, Tuple, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import sympy as sp\n",
        "import jax.numpy as jnp\n",
        "from jax import jacfwd\n",
        "from sympy import Eq, Rel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OptimizationConfig:\n",
        "    \"\"\"Configuration for the optimization algorithm.\"\"\"\n",
        "    max_iterations: int = 1000\n",
        "    input_file_path: Optional[str] = None\n",
        "    log_to_file: bool = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OptimizationProblem:\n",
        "    \"\"\"Represents an optimization problem with constraints.\"\"\"\n",
        "    target_function: Callable\n",
        "    target_expression: sp.Expr\n",
        "    x_symbols: List[sp.Symbol]\n",
        "    equalities: List[sp.Expr]\n",
        "    inequalities: List[sp.Expr]\n",
        "    lambda_symbols: List[sp.Symbol]\n",
        "    nu_symbols: List[sp.Symbol]\n",
        "    s_symbols: List[sp.Symbol]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class InitialPoint:\n",
        "    \"\"\"Initial values for optimization variables.\"\"\"\n",
        "    x: np.ndarray\n",
        "    s: np.ndarray\n",
        "    lambdas: np.ndarray\n",
        "    mu: float\n",
        "    epsilon: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_logger(log_to_file: bool) -> logging.Logger:\n",
        "    \"\"\"\n",
        "    Configure logger with console and optional file output.\n",
        "    \n",
        "    Args:\n",
        "        log_to_file: Whether to save logs to a file\n",
        "        \n",
        "    Returns:\n",
        "        Configured logger instance\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(\"interior_point_optimizer\")\n",
        "    logger.setLevel(logging.INFO)\n",
        "    logger.handlers.clear()\n",
        "    logger.propagate = False\n",
        "\n",
        "    # Console handler\n",
        "    console_handler = logging.StreamHandler(sys.stdout)\n",
        "    console_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    # File handler\n",
        "    if log_to_file:\n",
        "        logs_dir = Path(\"logs\")\n",
        "        logs_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "        file_path = logs_dir / f\"optimization_log_{timestamp}.txt\"\n",
        "        \n",
        "        file_handler = logging.FileHandler(file_path, encoding=\"utf-8\")\n",
        "        file_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_constraint(constraint_string: str) -> Tuple[Optional[str], Optional[sp.Expr]]:\n",
        "    \"\"\"\n",
        "    Parse a constraint string into its type and expression.\n",
        "    \n",
        "    Args:\n",
        "        constraint_string: String representation of the constraint\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (constraint_type, expression) where type is 'equality' or 'inequality'\n",
        "    \"\"\"\n",
        "    constraint_string = constraint_string.strip()\n",
        "\n",
        "    try:\n",
        "        # Handle equality constraints\n",
        "        if \"=\" in constraint_string and all(op not in constraint_string for op in [\">=\", \"<=\", \"!=\"]):\n",
        "            constraint_string = constraint_string.replace(\"==\", \"=\")\n",
        "            left, right = constraint_string.split(\"=\", 1)\n",
        "            lhs = sp.sympify(left)\n",
        "            rhs = sp.sympify(right)\n",
        "            return \"equality\", lhs - rhs\n",
        "        \n",
        "        # Handle inequality constraints\n",
        "        expr = sp.sympify(constraint_string)\n",
        "        \n",
        "        # Unwrap negations of equalities\n",
        "        while isinstance(expr, sp.Not) and isinstance(expr.args[0], sp.Eq):\n",
        "            expr = expr.args[0]\n",
        "\n",
        "        if isinstance(expr, Eq):\n",
        "            return \"equality\", expr.lhs - expr.rhs\n",
        "        elif isinstance(expr, Rel):\n",
        "            return \"inequality\", expr.lhs - expr.rhs\n",
        "        \n",
        "        return None, None\n",
        "        \n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error parsing constraint '{constraint_string}': {e}\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_problem_from_file(file_path: Path) -> Tuple[OptimizationProblem, InitialPoint]:\n",
        "    \"\"\"\n",
        "    Read optimization problem and initial values from file.\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to input file\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (OptimizationProblem, InitialPoint)\n",
        "    \"\"\"\n",
        "    if not file_path.exists():\n",
        "        raise FileNotFoundError(f\"File '{file_path}' does not exist!\")\n",
        "\n",
        "    x, s, lambdas, mu, epsilon = None, None, None, None, None\n",
        "    equalities, inequalities = [], []\n",
        "    target_expr = None\n",
        "    in_constraints_section = False\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            \n",
        "            # Skip empty lines and comments\n",
        "            if not line or line.startswith(\"#\"):\n",
        "                continue\n",
        "\n",
        "            # Check for constraints section\n",
        "            if line.lower().startswith(\"constraints\"):\n",
        "                in_constraints_section = True\n",
        "                continue\n",
        "\n",
        "            # Parse constraints\n",
        "            if in_constraints_section:\n",
        "                constraint_type, expr = parse_constraint(line)\n",
        "                if constraint_type == \"equality\":\n",
        "                    equalities.append(expr)\n",
        "                elif constraint_type == \"inequality\":\n",
        "                    inequalities.append(expr)\n",
        "                continue\n",
        "\n",
        "            # Parse key-value pairs\n",
        "            if \":\" not in line:\n",
        "                continue\n",
        "                \n",
        "            key, value = line.split(\":\", 1)\n",
        "            key = key.strip()\n",
        "            value = value.strip()\n",
        "\n",
        "            if key == \"target_function\":\n",
        "                target_expr = sp.sympify(value)\n",
        "            elif key == \"x\":\n",
        "                x = np.array([float(v) for v in value.split()])\n",
        "            elif key == \"s\":\n",
        "                s = np.array([float(v) for v in value.split()])\n",
        "            elif key == \"lambdas\":\n",
        "                lambdas = np.array([float(v) for v in value.split()])\n",
        "            elif key == \"mu\":\n",
        "                mu = float(value)\n",
        "            elif key in (\"epsilon\", \"eps\"):\n",
        "                epsilon = float(value)\n",
        "\n",
        "    # Create symbolic variables\n",
        "    x_symbols = sorted(target_expr.free_symbols, key=lambda s: s.name)\n",
        "    lambda_symbols = sp.symbols(f'λ1:{len(equalities) + 1}')\n",
        "    nu_symbols = sp.symbols(f'ν1:{len(inequalities) + 1}')\n",
        "    s_symbols = sp.symbols(f\"s1:{len(inequalities) + 1}\")\n",
        "\n",
        "    # Create problem and initial point\n",
        "    problem = OptimizationProblem(\n",
        "        target_function=sp.lambdify(x_symbols, target_expr),\n",
        "        target_expression=target_expr,\n",
        "        x_symbols=x_symbols,\n",
        "        equalities=equalities,\n",
        "        inequalities=inequalities,\n",
        "        lambda_symbols=list(lambda_symbols),\n",
        "        nu_symbols=list(nu_symbols),\n",
        "        s_symbols=list(s_symbols)\n",
        "    )\n",
        "\n",
        "    initial = InitialPoint(x=x, s=s, lambdas=lambdas, mu=mu, epsilon=epsilon)\n",
        "\n",
        "    return problem, initial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_lagrangian(\n",
        "    problem: OptimizationProblem,\n",
        "    mu: float\n",
        ") -> sp.Expr:\n",
        "    \"\"\"\n",
        "    Construct the Lagrangian with barrier terms.\n",
        "    \n",
        "    Args:\n",
        "        problem: Optimization problem specification\n",
        "        mu: Barrier parameter\n",
        "        \n",
        "    Returns:\n",
        "        Symbolic Lagrangian expression\n",
        "    \"\"\"\n",
        "    L = problem.target_expression\n",
        "    \n",
        "    # Add barrier terms for slack variables\n",
        "    L -= mu * sum(sp.log(s) for s in problem.s_symbols)\n",
        "    \n",
        "    # Add equality constraints\n",
        "    for lam, h in zip(problem.lambda_symbols, problem.equalities):\n",
        "        L += lam * h\n",
        "    \n",
        "    # Add inequality constraints with slack variables\n",
        "    for nu, g, s in zip(problem.nu_symbols, problem.inequalities, problem.s_symbols):\n",
        "        L += nu * (g + s)\n",
        "    \n",
        "    # Substitute ν = μ/s (complementarity condition)\n",
        "    nu_substitution = {nu: mu / s for nu, s in zip(problem.nu_symbols, problem.s_symbols)}\n",
        "    L = L.subs(nu_substitution)\n",
        "    \n",
        "    return L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_kkt_system(\n",
        "    lagrangian: sp.Expr,\n",
        "    x_symbols: List[sp.Symbol],\n",
        "    s_symbols: List[sp.Symbol],\n",
        "    lambda_symbols: List[sp.Symbol]\n",
        ") -> Callable:\n",
        "    \"\"\"\n",
        "    Create the KKT system of equations from the Lagrangian.\n",
        "    \n",
        "    Args:\n",
        "        lagrangian: Lagrangian expression\n",
        "        x_symbols: Decision variables\n",
        "        s_symbols: Slack variables\n",
        "        lambda_symbols: Lagrange multipliers\n",
        "        \n",
        "    Returns:\n",
        "        Function that computes KKT system residuals\n",
        "    \"\"\"\n",
        "    # Compute gradients\n",
        "    grad_x = [sp.diff(lagrangian, x) for x in x_symbols]\n",
        "    grad_lambda = [sp.diff(lagrangian, lam) for lam in lambda_symbols]\n",
        "    grad_s = [sp.diff(lagrangian, s) for s in s_symbols]\n",
        "    \n",
        "    # Combine all equations\n",
        "    system_equations = grad_x + grad_lambda + grad_s\n",
        "    all_symbols = list(x_symbols) + list(lambda_symbols) + list(s_symbols)\n",
        "    \n",
        "    # Create numerical function using JAX\n",
        "    system_func = sp.lambdify(all_symbols, system_equations, modules=\"jax\")\n",
        "    \n",
        "    def kkt_residual(y: jnp.ndarray) -> jnp.ndarray:\n",
        "        return jnp.array(system_func(*y))\n",
        "    \n",
        "    return kkt_residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def solve_interior_point(\n",
        "    initial: InitialPoint,\n",
        "    kkt_system: Callable,\n",
        "    max_iterations: int,\n",
        "    logger: logging.Logger\n",
        ") -> Tuple[np.ndarray, float, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Solve optimization problem using interior point method.\n",
        "    \n",
        "    Args:\n",
        "        initial: Initial values for all variables\n",
        "        kkt_system: Function computing KKT residuals\n",
        "        max_iterations: Maximum number of iterations\n",
        "        logger: Logger for progress tracking\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (optimal_x, optimal_lambda, optimal_s)\n",
        "    \"\"\"\n",
        "    # Combine all variables into single vector\n",
        "    y = jnp.array(np.concatenate([initial.x, initial.lambdas, initial.s]))\n",
        "    x_dim = len(initial.x)\n",
        "    s_dim = len(initial.s)\n",
        "    \n",
        "    for iteration in range(max_iterations):\n",
        "        # Compute KKT residuals\n",
        "        F = kkt_system(y)\n",
        "        residual = float(jnp.linalg.norm(F))\n",
        "        \n",
        "        logger.info(f'Residual: {residual}')\n",
        "        \n",
        "        # Check convergence\n",
        "        if residual < initial.epsilon:\n",
        "            logger.info(f\"Converged: {residual} < {initial.epsilon}\\n\")\n",
        "            break\n",
        "        \n",
        "        logger.info(\"\")\n",
        "        logger.info(f\"Iteration {iteration + 1}\")\n",
        "        logger.info(f'F(y{iteration}) = ({\", \".join(f\"{v:.6g}\" for v in F)})')\n",
        "        \n",
        "        # Compute Jacobian\n",
        "        J = jacfwd(kkt_system)(y)\n",
        "        logger.info(f'J(y{iteration}):\\n{J}')\n",
        "        \n",
        "        # Solve Newton system\n",
        "        delta = jnp.linalg.solve(J, -F)\n",
        "        logger.info(f'\\nΔ{iteration + 1} = ({\", \".join(f\"{v:.6g}\" for v in delta)})')\n",
        "        \n",
        "        # Backtracking line search to maintain s > 0\n",
        "        step = 1.0\n",
        "        max_backtrack = 20\n",
        "        \n",
        "        for _ in range(max_backtrack):\n",
        "            y_candidate = y + step * delta\n",
        "            s_new = y_candidate[-s_dim:]\n",
        "            \n",
        "            if np.all(s_new > 0):\n",
        "                break\n",
        "            \n",
        "            step *= 0.5\n",
        "            logger.info(f\"Slack variables would be negative. Reducing step to {step}\")\n",
        "        else:\n",
        "            logger.warning(\"Could not find valid step maintaining s > 0. Stopping.\")\n",
        "            break\n",
        "        \n",
        "        # Update variables\n",
        "        y = y_candidate\n",
        "        logger.info(f'y{iteration + 1} = ({\", \".join(f\"{v:.6g}\" for v in y)})')\n",
        "        \n",
        "        # Log new residual\n",
        "        F_new = kkt_system(y)\n",
        "        logger.info(f'F(y{iteration + 1}) = ({\", \".join(f\"{v:.6g}\" for v in F_new)})\\n')\n",
        "    else:\n",
        "        logger.info(\"Maximum iterations reached.\")\n",
        "    \n",
        "    # Extract solution components\n",
        "    x_opt = y[:x_dim]\n",
        "    lambda_opt = y[x_dim]\n",
        "    s_opt = y[x_dim + 1:]\n",
        "    \n",
        "    return x_opt, lambda_opt, s_opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_initial_parameters(\n",
        "    initial: InitialPoint,\n",
        "    problem: OptimizationProblem,\n",
        "    logger: logging.Logger\n",
        ") -> None:\n",
        "    \"\"\"Log initial parameter values.\"\"\"\n",
        "    logger.info('Initial Parameters:\\n')\n",
        "    \n",
        "    logger.info('Initial approximation x:')\n",
        "    for i, val in enumerate(initial.x, 1):\n",
        "        logger.info(f'x{i} = {val}')\n",
        "    logger.info('')\n",
        "    \n",
        "    logger.info('Initial slack variables s:')\n",
        "    for i, val in enumerate(initial.s, 1):\n",
        "        logger.info(f's{i} = {val}')\n",
        "    \n",
        "    logger.info('Initial Lagrange multipliers λ:')\n",
        "    for i, val in enumerate(initial.lambdas, 1):\n",
        "        logger.info(f'λ{i} = {val}')\n",
        "    logger.info('')\n",
        "    \n",
        "    logger.info(f'μ = {initial.mu}')\n",
        "    logger.info(f'ε = {initial.epsilon}\\n')\n",
        "\n",
        "\n",
        "def log_solution(\n",
        "    x_opt: np.ndarray,\n",
        "    lambda_opt: float,\n",
        "    s_opt: np.ndarray,\n",
        "    target_function: Callable,\n",
        "    logger: logging.Logger\n",
        ") -> None:\n",
        "    \"\"\"Log the optimal solution.\"\"\"\n",
        "    logger.info('Optimal Solution:')\n",
        "    \n",
        "    for i, val in enumerate(x_opt, 1):\n",
        "        logger.info(f'x{i}* = {val}')\n",
        "    \n",
        "    logger.info(f'λ* = {lambda_opt}')\n",
        "    \n",
        "    for i, val in enumerate(s_opt, 1):\n",
        "        logger.info(f's{i}* = {val}')\n",
        "    \n",
        "    obj_value = target_function(*x_opt)\n",
        "    logger.info(f'Objective function value F(x*) = {obj_value}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Parameters:\n",
            "\n",
            "Initial approximation x:\n",
            "x1 = 1.0\n",
            "x2 = 1.0\n",
            "x3 = 1.0\n",
            "\n",
            "Initial slack variables s:\n",
            "s1 = 1.0\n",
            "s2 = 1.0\n",
            "Initial Lagrange multipliers λ:\n",
            "λ1 = 0.0\n",
            "\n",
            "μ = 0.1\n",
            "ε = 0.001\n",
            "\n",
            "Newton's Method:\n",
            "\n",
            "Residual: 3.753664970397949\n",
            "\n",
            "Iteration 1\n",
            "F(y0) = (2.2, 2.2, 2.1, 0, -0, -0)\n",
            "J(y0):\n",
            "[[ 2.2  0.   0.   2.  -0.2  0. ]\n",
            " [ 0.   2.2  0.   1.  -0.2  0. ]\n",
            " [ 0.   0.   2.2  0.  -0.2  0.1]\n",
            " [ 2.   1.   0.   0.   0.   0. ]\n",
            " [-0.2 -0.2 -0.2  0.  -0.1  0. ]\n",
            " [ 0.   0.   0.1  0.   0.  -0.1]]\n",
            "\n",
            "Δ1 = (0.166558, -0.333116, -0.753102, -1.09928, 1.83932, -0.753102)\n",
            "y1 = (1.16656, 0.666884, 0.246898, -1.09928, 2.83932, 0.246898)\n",
            "F(y1) = (-0.149464, 0.281462, 0.10616, 0.0277414, -0.00875581, -9.77792e-08)\n",
            "\n",
            "Residual: 0.3371596038341522\n",
            "\n",
            "Iteration 2\n",
            "F(y1) = (-0.149464, 0.281462, 0.10616, 0.0277414, -0.00875581, -9.77792e-08)\n",
            "J(y1):\n",
            "[[-0.12812372  0.          0.          2.3331156  -0.02894059  0.        ]\n",
            " [ 0.          2.0704393   0.          1.         -0.01654443  0.        ]\n",
            " [ 0.          0.          2.0704393   0.         -0.00612517  1.6404628 ]\n",
            " [ 2.3331156   1.          0.          0.          0.          0.        ]\n",
            " [-0.02894059 -0.01654442 -0.00612517  0.         -0.00623673  0.        ]\n",
            " [ 0.          0.          1.6404626   0.          0.         -1.6404618 ]]\n",
            "\n",
            "Δ2 = (0.0613689, -0.170922, -0.0305969, 0.052482, -1.20522, -0.030597)\n",
            "y2 = (1.22793, 0.495962, 0.216301, -1.0468, 1.6341, 0.216301)\n",
            "F(y2) = (0.0353553, 0.00582666, -0.00324497, 0.0037663, 0.0211714, 3.18497e-08)\n",
            "\n",
            "Residual: 0.04191524535417557\n",
            "\n",
            "Iteration 3\n",
            "F(y2) = (0.0353553, 0.00582666, -0.00324497, 0.0037663, 0.0211714, 3.18497e-08)\n",
            "J(y2):\n",
            "[[ 0.02879263  0.          0.          2.4558535  -0.09197006  0.        ]\n",
            " [ 0.          2.1223917   0.          1.         -0.03714691  0.        ]\n",
            " [ 0.          0.          2.1223917   0.         -0.01620062  2.137394  ]\n",
            " [ 2.4558535   1.          0.          0.          0.          0.        ]\n",
            " [-0.09197006 -0.03714691 -0.01620062 -0.         -0.06336133 -0.        ]\n",
            " [-0.         -0.          2.137394   -0.         -0.         -2.1373942 ]]\n",
            "\n",
            "Δ3 = (-0.00315116, 0.00397248, 0.00203909, -0.00178163, 0.335861, 0.00203911)\n",
            "y3 = (1.22478, 0.499935, 0.21834, -1.04858, 1.96996, 0.21834)\n",
            "F(y3) = (0.00534346, 0.00204421, 0.000844417, 9.77516e-06, 0.00598752, -0)\n",
            "\n",
            "Residual: 0.008324352093040943\n",
            "\n",
            "Iteration 4\n",
            "F(y3) = (0.00534346, 0.00204421, 0.000844417, 9.77516e-06, 0.00598752, -0)\n",
            "J(y3):\n",
            "[[ 0.00436275  0.          0.          2.449551   -0.06312079  0.        ]\n",
            " [ 0.          2.101525    0.          1.         -0.02576495  0.        ]\n",
            " [ 0.          0.          2.101525    0.         -0.01125249  2.0976577 ]\n",
            " [ 2.449551    1.          0.          0.          0.          0.        ]\n",
            " [-0.06312079 -0.02576495 -0.01125249 -0.         -0.03184713 -0.        ]\n",
            " [ 0.          0.          2.0976577   0.          0.         -2.0976577 ]]\n",
            "\n",
            "Δ4 = (-3.05078e-05, 6.49553e-05, 0.000302446, 0.00266075, 0.187909, 0.000302446)\n",
            "y4 = (1.22475, 0.5, 0.218642, -1.04592, 2.15787, 0.218642)\n",
            "F(y4) = (0.0010328, 0.000421055, 0.000180569, 0, 0.000951981, -0)\n",
            "\n",
            "Residual: 0.001477442099712789\n",
            "\n",
            "Iteration 5\n",
            "F(y4) = (0.0010328, 0.000421055, 0.000180569, 0, 0.000951981, -0)\n",
            "J(y4):\n",
            "[[ 8.4335357e-04  0.0000000e+00  0.0000000e+00  2.4494901e+00\n",
            "  -5.2604903e-02  0.0000000e+00]\n",
            " [ 0.0000000e+00  2.0926840e+00  0.0000000e+00  1.0000000e+00\n",
            "  -2.1475844e-02  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  2.0926840e+00  0.0000000e+00\n",
            "  -9.3910554e-03  2.0918581e+00]\n",
            " [ 2.4494901e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [-5.2604899e-02 -2.1475844e-02 -9.3910554e-03 -0.0000000e+00\n",
            "  -2.2358192e-02 -0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  2.0918581e+00  0.0000000e+00\n",
            "   0.0000000e+00 -2.0918581e+00]]\n",
            "\n",
            "Δ5 = (-1.13781e-07, 2.78705e-07, 5.23554e-05, 0.000492302, 0.0425566, 5.23554e-05)\n",
            "y5 = (1.22474, 0.5, 0.218695, -1.04543, 2.20042, 0.218695)\n",
            "F(y5) = (4.35486e-05, 1.7684e-05, 7.65175e-06, 0, 3.61134e-05, -0)\n",
            "\n",
            "Residual: 5.9765647165477276e-05\n",
            "Converged: 5.9765647165477276e-05 < 0.001\n",
            "\n",
            "Optimal Solution:\n",
            "x1* = 1.2247449159622192\n",
            "x2* = 0.4999999701976776\n",
            "x3* = 0.2186945080757141\n",
            "λ* = -1.0454280376434326\n",
            "s1* = 2.2004241943359375\n",
            "s2* = 0.2186945080757141\n",
            "Objective function value F(x*) = 1.7978273630142212\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    # Configuration\n",
        "    config = OptimizationConfig(\n",
        "        max_iterations=1000,\n",
        "        input_file_path=\"input.txt\",  # Set to filename for file input\n",
        "        log_to_file=True\n",
        "    )\n",
        "    \n",
        "    logger = setup_logger(config.log_to_file)\n",
        "    \n",
        "    # Load problem (implement interactive input if needed)\n",
        "    if config.input_file_path:\n",
        "        problem, initial = read_problem_from_file(Path(config.input_file_path))\n",
        "    else:\n",
        "        raise NotImplementedError(\"Interactive input not implemented in refactored version\")\n",
        "    \n",
        "    # Build optimization problem\n",
        "    lagrangian = create_lagrangian(problem, initial.mu)\n",
        "    kkt_system = create_kkt_system(\n",
        "        lagrangian,\n",
        "        problem.x_symbols,\n",
        "        problem.s_symbols,\n",
        "        problem.lambda_symbols\n",
        "    )\n",
        "    \n",
        "    # Log initial state\n",
        "    log_initial_parameters(initial, problem, logger)\n",
        "    logger.info(\"Newton's Method:\\n\")\n",
        "    \n",
        "    # Solve\n",
        "    x_opt, lambda_opt, s_opt = solve_interior_point(\n",
        "        initial,\n",
        "        kkt_system,\n",
        "        config.max_iterations,\n",
        "        logger\n",
        "    )\n",
        "    \n",
        "    # Log results\n",
        "    log_solution(x_opt, lambda_opt, s_opt, problem.target_function, logger)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
